{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2418e9f4-2690-4207-808d-99cb902ad1be",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- process of using domain knowledge to extract features from raw data via data mining techniques\n",
    "> Domain knowledge referes to the field of experties. A data scientist is not always an expert in every domain. In such case he/she can consult with a domain expert to disucss the importance of features or extract more features from a feature.\n",
    "\n",
    "## 1. Extract Information\n",
    "- For example, a feature with timestamp as `year-month-day,hour:minute:second` as it is very difficult to pass in a machine learning algorithms.\n",
    "- It is because for example in linear regression a coefficient is multiplied with a feature which makes no sense with such timestamps\n",
    "- We need to make sure such data needs to be either a floatinig point number or an integer number (some might be categorical in string but again they need to be encoded so from the algorithm's prespective there are only floating point or integer numbers)\n",
    "- Such features like timestamps can be used to extract infromation as:\n",
    "    - Year, month\n",
    "    - weekday/weekend (0/1)\n",
    "    - Integer encoding (Sun: 0 , Mon: 1, .... Sat: 6)\n",
    "- More complex example could be:\n",
    "    - Again we obviously can't multiply coefficient with a text data\n",
    "    - But we can extract numerical data from a text data\n",
    "    - Length of text, number of occurance of a word/alphabet\n",
    "    - This falls under Natural Language Processing (NLP) which I'll learn later\n",
    "\n",
    "## 2. Combining Information\n",
    "- It's just the opposite to ectracting information, where we combine multiple features to a single\n",
    "- For example from two features hour and minute of a day we can engineer a new feature which describes day or night (0/1)\n",
    "- Or from integer encoded days to weekdays or weekend (0/1)\n",
    "\n",
    "## 3. Transforming Information\n",
    "- Refers to the transformation of a categorical information into encoded features\n",
    "    - Integer Encoding\n",
    "        - Directly converting categories into integers as 1,2,3,....,n\n",
    "        - The problem with integer enconding is that a machine learning algorithms will not understand it as a categorical information rather some sort of linear data.\n",
    "        - Another problem is it may imply some relationship between data for example, a category-3 as 3 times a category-1 (in the data 1,2,3,4....n)\n",
    "        - Integer encoding could be suitable for a feature representing category as well as levels.\n",
    "        - For example: spice level as mild, hot, fire as (1,2,3). Here we can say that fire spicy than mild.\n",
    "        - Integer encoding doesnot increase the number of features we can directly map categorical feature to integer feature.\n",
    "        \n",
    "    - One-hot Encoding (Dummy Variables)\n",
    "      - Converts each category into individual features that are either 0 or 1\n",
    "      - For a feature with lots of categories it may be inappropriate to one-hot encode all of them\n",
    "      - In such case we may requre to consider higher level categories.\n",
    "      - For example a work class in each country will generate immense number of dummy categories. In such case it is appropriate to create higher level category as continental category.\n",
    "        > NOTE: It requres lot of tuning and domain experince to choose higher level categories or mappings\n",
    "      - Problem:\n",
    "        - Dummy variable trap, mathematically known as multi-collinearity\n",
    "        - For example a features with 2 categories where they are alternate of one another\n",
    "        - In such case creating a dummy variable using one-hot encoding seems unnecessary.\n",
    "        - For example, in yes/no category, creating two feature will have collinearity. While one is true other is false.\n",
    "        - They can be always encoded within a single feature as (0/1) or create a dummy variables and drop one.\n",
    "\n",
    "\n",
    "# Outliers\n",
    "- Outliers are the data points that are typically not in range where maximum data points reside.\n",
    "- The selction of outliers requires a domain knowledge\n",
    "- Outliers are defined domain dependent metrics like\n",
    "    - Range and limits\n",
    "        - Inter-Quartile Range (IQR)\n",
    "        - Standart Deviation\n",
    "        - Visualized or domain limit value (example: a domain expert may recommend a price above or below is not really practicle for the current market)\n",
    "    - Percentage of data\n",
    "        - If large percentage of data is labeled as an outlier, then it is not an outlier rather we have wide distribution of data\n",
    "        - We should limit outliers to few percentage of data. (for example, in 100 datapoints it is not appropriate to select 20 data points as outliers.)\n",
    "\n",
    "## Outlier Consideration\n",
    "- Utilize visualizations (such as scatterplot) to be able to see and identify if some data are out of range\n",
    "- Consult with domain expert to identify the range and aspects of outliers, and make a warning or suggestion to apply in the ML models. (for example: model is not suitable for house priced over $10 Million)\n",
    "- There is no 100% correct outlier methodology that is applicable for all situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602c40b-23e6-4420-9f70-39c29c253d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
